{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os \n\nimport matplotlib.pyplot as plt\n\nimport wandb\n\nimport cv2 as cv\n\nfrom sklearn.model_selection import train_test_split, KFold\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torch import nn\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.nn.functional import conv2d, relu, pad\n\nfrom pytorch_lightning import metrics\nfrom pytorch_lightning import LightningDataModule, LightningModule, Trainer\nfrom pytorch_lightning.loggers import WandbLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping\n\nfrom transformers import AdamW\n\nfrom tqdm.notebook import tqdm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport random","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"! pip install knockknock --quiet\n\n# Importation\nfrom knockknock import telegram_sender \nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\ntoken = user_secrets.get_secret(\"token\")\nchat_id = user_secrets.get_secret(\"chat_id\")\n\n@telegram_sender(token=token, chat_id=int(chat_id))\ndef send_msg(msg):\n    print()\n    return msg\nsend_msg('End')","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncaip-notebooks-serverextension 1.0.0 requires pyjwt>=2.0.0requests>=2.22.0, but you have pyjwt 1.7.1 which is incompatible.\u001b[0m\n\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'End'"},"metadata":{}}]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\n\n# I have saved my API token with \"wandb_api\" as Label. \n# If you use some other Label make sure to change the same below. \nwandb_api = user_secrets.get_secret(\"wandb_api\") \n\nwandb.login(key=wandb_api)","metadata":{"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"def seed_everything(seed=1234):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n# seed_everything()","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Reading dataset","metadata":{}},{"cell_type":"code","source":"DATA_PATH='/kaggle/input/plant-pathology-2021-fgvc8/'\n\ntrain_df=pd.read_csv(DATA_PATH+'train.csv').sample(frac=1.)\n\ntrain_df['image_path']=train_df.image.apply(lambda x: DATA_PATH+'train_images/'+x)","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Label extraction","metadata":{}},{"cell_type":"code","source":"class AdaptLabels:\n    \n    def five_cats(self, X, N=-1):\n        X = X.copy()\n        labels=list(set([u for t in X.labels.unique() for u in t.split()]))\n        labels.sort()\n        \n        for label in labels:\n            X[label] = X.labels.apply(lambda x: 1*(label in x))\n\n        X.drop(['image','labels'],axis=1,inplace=True)\n\n        inds=[]\n        for label in labels:\n            inds.extend(X[X[label]==1].iloc[:N].index)\n        inds=list(set(inds))\n\n        X = X.iloc[inds].reset_index(drop=True)\n\n        X, y = X.image_path.to_numpy(), X.drop(['image_path','healthy'],axis=1).to_numpy()\n        \n        return X, y\n    \n    def six_cats(self, X, N=-1):\n        X = X.copy()\n        labels=list(set([u for t in X.labels.unique() for u in t.split()]))\n        labels.sort()\n        \n        for label in labels:\n            X[label] = X.labels.apply(lambda x: 1*(label in x))\n\n        X.drop(['image','labels'],axis=1,inplace=True)\n\n        inds=[]\n        for label in labels:\n            inds.extend(X[X[label]==1].iloc[:N].index)\n        inds=list(set(inds))\n\n        X = X.iloc[inds].reset_index(drop=True)\n\n        X, y = X.image_path.to_numpy(), X.drop('image_path',axis=1).to_numpy()\n        \n        return X, y\n    \n    def twelve_cats(self,X):\n        X = X.copy()\n        labels = list(X.labels.unique())\n        labels.sort()\n        \n        encoder = {k:v for v,k in enumerate(labels)}\n        \n        X.labels = X.labels.apply(lambda x: encoder[x])\n        \n        X, y = X.image_path.to_numpy(), X.labels.to_numpy()\n        \n        return X, y\n    \n    def all_cats(self,X):\n        X = X.copy()\n        labels=list(set([u for t in X.labels.unique() for u in t.split()]))\n        labels.remove('healthy')\n        labels.sort()\n        \n        def get_indx(x):\n            indx = 0\n            for i,label in enumerate(labels):\n                if label in x:\n                    indx+=2**i\n            return indx\n        \n        X.labels = X.labels.apply(get_indx)\n        \n        X, y = X.image_path.to_numpy(), X.labels.to_numpy()\n        \n        return X, y\n\n        \n        \nadapter = AdaptLabels()\n# X, y_five = adapter.five_cats(train_df)\nX, y = adapter.six_cats(train_df)\n# _, y_twelve = adapter.twelve_cats(train_df)\n# _, y_thirty = adapter.all_cats(train_df)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## torch Dataset","metadata":{}},{"cell_type":"code","source":"class LeafDataset(Dataset):\n    \n    def __init__(self, X = None, y = None, begin = 0, end = -1, data = None):\n        super().__init__()\n                \n        if data is not None:\n            self.n = len(data)\n            self.data = data\n            return \n        \n        self.transforms=A.Compose([\n                A.Resize(428, 428),\n                ToTensorV2()\n        ])\n                        \n\n        self.data=[]\n        with tqdm(total=X.shape[0]) as pbar:\n            for x, label in zip(X,y):\n                img=self.load_img(x)\n                self.data.append([img,torch.tensor(label)])\n                pbar.update(1)  \n    \n    def change_labels(self,y):\n        for i in range(len(self.data)):\n            self.data[i][1] = y[i]\n    \n    \n    def load_img(self,x):\n        img = cv.imread(x, cv.IMREAD_UNCHANGED)\n        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n        img = self.transforms(image = img)['image']\n        return img\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def get_dataset(self, data):\n        return LeafDataset(data=data)\n    \n    def slice(self, i):\n        if isinstance(i, slice):\n            indices = range(*i.indices(len(self.data)))\n            t = [self.data[ii] for ii in indices]\n        if isinstance(i, list):\n            t = [self.data[ii] for ii in i]\n        return self.get_dataset(t)\n    \n    def __getitem__(self,i):\n        return self.data[i]\n    \ntrain_dataset = LeafDataset(X, y)\nsend_msg('End')","metadata":{"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18627 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80b01b36fd3a46e7bdaeaf86d7700f4e"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'End'"},"metadata":{}}]},{"cell_type":"markdown","source":"## PL  Datamodule","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import random_split\n\nclass LeafDM(LightningDataModule):\n    \n    def __init__(self,train = None, val = None, data = None, y=None, batch_size=16):\n        super().__init__()\n                \n        if data:\n            self.data = data\n            if y is not None:\n                self.data.change_labels(y)\n        else:\n            self.train = train\n            self.val = val\n            if y is not None:\n                self.train.change_labels(y)\n                self.val.change_labels(y)\n            \n        self.batch_size = batch_size\n        \n    def setup(self, stage=None):\n        if hasattr(self, 'data'):\n            n = len(self.data)\n            val, test = 512, 4 # int(n*.2), int(n*.2)\n            train = n - (val + test)\n            self.train, self.val, self.test = random_split(self.data, [train, val ,test] )\n        else:\n            n = len(self.train)\n            test = int(n*.1)\n            train = n - test\n            self.train, self.test = random_split(self.train, [train, test] )\n        \n    def train_dataloader(self):\n        return DataLoader(self.train, batch_size=self.batch_size, num_workers=2, prefetch_factor=4,\n                         pin_memory=True, shuffle=True)\n    \n    def val_dataloader(self):\n        return DataLoader(self.val, batch_size=self.batch_size, num_workers=2, prefetch_factor=4,\n                         pin_memory=True)\n    \n    def test_dataloader(self):\n        return DataLoader(self.test, batch_size=self.batch_size, num_workers=2, prefetch_factor=4,\n                         pin_memory=True)","metadata":{"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'End'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"from torch import nn\nfrom torchvision import transforms as T\n\nclass Preprocess(nn.Module):\n    \n    def __init__(self):\n        # input should be a 256 by 256 tensor.\n        super().__init__()\n        \n        self.augment = nn.Sequential(\n            T.RandomCrop((400, 400)),\n            T.RandomApply(nn.ModuleList([T.CenterCrop((385,385))]),p=.5),\n            T.RandomHorizontalFlip(.5),\n            T.RandomVerticalFlip(.5),\n            T.RandomErasing(p=.2,scale=(0.02, 0.02)), \n            T.RandomApply(nn.ModuleList([T.RandomRotation(170)]),p=.2),\n        )\n        \n        self.normalize = nn.Sequential(\n            T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        )\n        \n    def forward(self,x):\n        x = x / 255\n        x = self.augment(x)\n        return self.normalize(x)","metadata":{"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"! pip install efficientnet_pytorch --quiet\nfrom efficientnet_pytorch import EfficientNet\n\nclass Model(LightningModule):\n    \n    def __init__(self, lr=5e-4, betas=(.8, .9),weight_decay=10.,drop1=.3, drop2=.1 ):\n        super().__init__()\n        \n        self.save_hyperparameters()\n        \n        self.cost = nn.BCEWithLogitsLoss()\n                        \n        self.preprocess = Preprocess()\n        \n        def load_effnet(i,out):\n            effnet = EfficientNet.from_pretrained('efficientnet-b'+str(i))\n            n_features = effnet._fc.in_features\n            effnet._dropout = nn.Dropout(self.hparams.drop1)\n            effnet._fc = nn.Sequential(\n                            nn.Linear(n_features, 1000),nn.ReLU(),\n                            nn.Dropout(self.hparams.drop2),\n                            nn.Linear(1000, out)\n            )\n            return effnet\n        \n        self.effnet = load_effnet(5,6)\n        \n        \n    def forward(self,x):\n        x = self.preprocess(x)\n        x = self.effnet(x)\n        return x\n    \n    def calc_cost(self, preds, labels):\n        cost = self.cost(preds, labels)\n        return cost\n                \n    def configure_optimizers(self):\n        opt = AdamW(self.parameters(), lr = self.hparams.lr,\n                  betas = self.hparams.betas, weight_decay = self.hparams.weight_decay)\n        lr_scheduler = StepLR(opt, step_size=1, gamma=.5)\n\n        return [opt], [lr_scheduler]\n    \n    def training_step(self, batch, batch_idx):\n        imgs, labels = batch\n        preds = self(imgs)\n        cost = self.calc_cost(preds, labels.float())\n        self.log('train_loss', cost, logger=True, on_epoch=True, prog_bar=True)\n\n        return cost\n    \n    def validation_step(self, batch, batch_idx):\n        imgs, labels = batch\n        preds = self(imgs)\n        cost = self.calc_cost(preds, labels.float())\n        self.log('val_loss', cost, prog_bar=True)\n\n        return cost\n    \n    def test_step(self, batch, batch_idx):\n        imgs, labels = batch\n        preds = self(imgs)\n        cost = self.calc_cost(preds, labels.float())\n        self.log('test_loss', cost, prog_bar=True, logger=True)","metadata":{"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"dm = LeafDM(data=train_dataset, batch_size=8)\ndm.setup()\n\nmodel = Model()\n\ncheckpoint_callback = ModelCheckpoint(\n                                  monitor='val_loss',\n                                  save_top_k = 10, mode = 'min', save_weights_only=True,\n                                  filename = 'Model-{val_loss:.2f}',\n                                  dirpath = '/kaggle/working/Models',\n                                  save_last = False\n                                 )\n\nlr_monitor = LearningRateMonitor(logging_interval='epoch')\n\nwandb_logger = WandbLogger(project='PP21', entity='aita3ssis')\n\ntrainer = Trainer(\n                logger = wandb_logger,\n                callbacks = [checkpoint_callback, lr_monitor],\n                gpus = -1, max_epochs = 12,\n                accumulate_grad_batches = 64,\n                check_val_every_n_epoch = 1,\n#                 limit_train_batches=512,\n#                 limit_val_batches = 512,\n)\ntrainer.fit(model, dm)\ntrainer.test(ckpt_path = checkpoint_callback.best_model_path)\n\n\nwandb.finish()\nsend_msg('End')","metadata":{"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Loaded pretrained weights for efficientnet-b5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: Checkpoint directory /kaggle/working/Models exists and is not empty.\n  warnings.warn(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                Tracking run with wandb version 0.10.26<br/>\n                Syncing run <strong style=\"color:#cdcd00\">zany-wind-323</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/aita3ssis/PP21\" target=\"_blank\">https://wandb.ai/aita3ssis/PP21</a><br/>\n                Run page: <a href=\"https://wandb.ai/aita3ssis/PP21/runs/2n8ie05i\" target=\"_blank\">https://wandb.ai/aita3ssis/PP21/runs/2n8ie05i</a><br/>\n                Run data is saved locally in <code>/kaggle/working/wandb/run-20210516_203219-2n8ie05i</code><br/><br/>\n            "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation sanity check: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4e6dee3308d4a339a51e8e3bf2d8f9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n  warnings.warn(*args, **kwargs)\nException in thread Thread-55:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n    return _ForkingPickler.loads(res)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n    fd = df.detach()\n  File \"/opt/conda/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n    with _resource_sharer.get_connection(self._id) as conn:\n  File \"/opt/conda/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n    c = Client(address, authkey=process.current_process().authkey)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 492, in Client\n    c = SocketClient(address)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 620, in SocketClient\n    s.connect(address)\nFileNotFoundError: [Errno 2] No such file or directory\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18995af59c63457099f70a68d45b7782"}},"metadata":{}},{"name":"stdout","text":"--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_loss': 0.041360363364219666}\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br/>Waiting for W&B process to finish, PID 9171<br/>Program ended successfully."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find user logs for this run at: <code>/kaggle/working/wandb/run-20210516_203219-2n8ie05i/logs/debug.log</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210516_203219-2n8ie05i/logs/debug-internal.log</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>lr-AdamW</td><td>0.0</td></tr><tr><td>trainer/global_step</td><td>329</td></tr><tr><td>_runtime</td><td>9223</td></tr><tr><td>_timestamp</td><td>1621206362</td></tr><tr><td>_step</td><td>34</td></tr><tr><td>train_loss_epoch</td><td>0.08343</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>val_loss</td><td>0.06469</td></tr><tr><td>train_loss_step</td><td>0.0238</td></tr><tr><td>test_loss</td><td>0.04136</td></tr></table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>lr-AdamW</td><td>█▄▃▂▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>_runtime</td><td>▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▆▆▆▆▆▇▇▇█</td></tr><tr><td>val_loss</td><td>█▃▂▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▂▇▁▃</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                    <br/>Synced <strong style=\"color:#cdcd00\">zany-wind-323</strong>: <a href=\"https://wandb.ai/aita3ssis/PP21/runs/2n8ie05i\" target=\"_blank\">https://wandb.ai/aita3ssis/PP21/runs/2n8ie05i</a><br/>\n                "},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'End'"},"metadata":{}}]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cross validation","metadata":{}},{"cell_type":"code","source":"# yss = [ y_five, y_six, y_twelve, y_thirty]\n# outs = [5, 6, 12, 32]\n# costs = [ nn.BCEWithLogitsLoss, nn.BCEWithLogitsLoss, nn.CrossEntropyLoss, nn.CrossEntropyLoss ]\n\n# kfold = KFold(n_splits = len(yss), shuffle = False)\n\n# for i, (train_inds, test_inds) in enumerate(kfold.split(train_dataset)):\n    \n#     train = train_dataset.slice(train_inds.tolist())\n#     val = train_dataset.slice(test_inds.tolist())\n    \n#     dm = LeafDM(train = train, val = val, y = yss[i])    \n    \n#     model = Model(out=outs[i], cost=costs[i])\n    \n#     checkpoint_callback = ModelCheckpoint(\n#                                       monitor='val_loss',\n#                                       save_top_k=1, mode='min', save_weights_only=True,\n#                                       filename=str(i)+'-{val_loss:.2f}',\n#                                       dirpath='/kaggle/working/Modelssss',\n#                                       save_last=False\n#                                      )\n#     lr_monitor = LearningRateMonitor(logging_interval='epoch')\n\n#     wandb_logger = WandbLogger(project='PP21', entity='aita3ssis')\n\n#     trainer = Trainer(\n#                     logger = wandb_logger,\n#                     callbacks = [checkpoint_callback, lr_monitor],\n#                     gpus = -1, max_epochs = 10,\n#                     accumulate_grad_batches = 32,\n#                     check_val_every_n_epoch = 1,\n# #                     limit_train_batches=51,\n# #                     limit_val_batches = 51,\n# #                     log_every_n_steps=40,\n# #                     flush_logs_every_n_steps=40,\n#     )\n#     trainer.fit(model, datamodule=dm)\n#     trainer.test(ckpt_path = checkpoint_callback.best_model_path)\n    \n\n#     a = '009e1e49ab176827fce64df70c2ccafe103866fc'\n#     wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = Model.load_from_checkpoint(checkpoint_path='./Modelssss/2-val_loss=0.11.ckpt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Postprocessing","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom sklearn.metrics import f1_score\n\nclass Postprocess:\n    \n    def __init__(self):\n        pass\n    \n    def get_predictions(self,model, dataset):\n        loader = DataLoader(dataset, batch_size=8, shuffle=False)\n        \n        device='cuda' if torch.cuda.is_available() else 'cpu'\n        \n        model.to(device)\n        model.eval()\n        \n        # Generate predictions\n        preds = []\n        truth=[]\n        with tqdm(total=len(loader)) as pbar:\n            for i,(x, label) in enumerate(loader):\n                y_hat=model(x.to(device)).sigmoid().detach().cpu()\n                preds.extend(list(y_hat.numpy()))\n                truth.extend(list(label.numpy()))\n                pbar.update(1)\n                \n        preds=np.vstack(preds)\n        truth=np.vstack(truth)\n        \n        return truth, preds\n    \n    def find_thresholds(self,truth, preds, N=10):        \n        # Find optimal threshold\n        thresholds = np.random.rand(1,truth.shape[1])\n        best = thresholds\n        best_score = 0\n        with tqdm(total=N) as pbar:\n            for i in range(N):\n                tmp_preds = (preds >= thresholds)*1\n                score = f1_score(truth, tmp_preds, average='macro')\n                if best_score < score:\n                    best_score = score\n                    best = thresholds\n                thresholds = np.random.rand(1,truth.shape[1])\n                pbar.update(1)\n                pbar.set_postfix({'best_score':best_score})\n            \n        labels = (preds >= best)*1\n        \n        return labels, best, best_score\n    \npostprocess = Postprocess()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback.best_model_path","metadata":{"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/Models/Model-val_loss=0.06.ckpt'"},"metadata":{}}]},{"cell_type":"code","source":"model = Model.load_from_checkpoint(checkpoint_path = checkpoint_callback.best_model_path)\ntruth, preds = postprocess.get_predictions(model, train_dataset[2::10])\nlabels, threshold, score = postprocess.find_thresholds(truth, preds, N=2000)\nprint(threshold)","metadata":{"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Loaded pretrained weights for efficientnet-b5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/233 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b20b45204fd54166a805dda1a021224b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e7bb19cc2e94cae9184bf49fc937c68"}},"metadata":{}},{"name":"stdout","text":"[[0.43978631 0.44070179 0.35533386 0.73467215 0.68395072 0.3390692 ]]\n","output_type":"stream"}]},{"cell_type":"code","source":"labels, threshold, score = postprocess.find_thresholds(truth, preds, N=2000)\nprint(threshold)","metadata":{"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b11e5fd4d2784e58812703a2c5bf7bf5"}},"metadata":{}},{"name":"stdout","text":"[[0.51392244 0.49471279 0.16051167 0.68841642 0.34478749 0.52866761]]\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'credible_model.pth')","metadata":{"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score, multilabel_confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n\nclass Evaluation:\n    \n    def f1_score(self, pred, truth):\n        return f1_score(truth,pred,average='macro')\n    \n    def accuracy(self, pred, truth):\n        return accuracy_score(truth,pred)\n    \n    def confusion_matrix(self, pred, truth):\n        matrices = multilabel_confusion_matrix(truth, pred)\n        \n        return matrices\n\nevaluate = Evaluation()","metadata":{"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"evaluate.confusion_matrix(labels, truth)","metadata":{"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"array([[[1625,   36],\n        [  52,  150]],\n\n       [[1417,   35],\n        [  32,  379]],\n\n       [[1345,    9],\n        [   3,  506]],\n\n       [[1736,    6],\n        [   3,  118]],\n\n       [[1635,   24],\n        [   3,  201]],\n\n       [[1282,   25],\n        [  60,  496]]])"},"metadata":{}}]},{"cell_type":"markdown","source":"## Visualization\n> * Pick some images and check their predictions\n> * Visualize some submodule's output map\n> * Check convolutions used in the first Conv block.","metadata":{}},{"cell_type":"code","source":"for count, filename in enumerate(os.listdir(\"Models\")):\n    src = 'Models/'+filename\n    dst = src.replace('a','.')\n          \n        # rename() function will\n        # rename all the files\n    os.rename(src, dst)","metadata":{"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"! ls Models","metadata":{"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"0.06.ckpt     0.06bv2.ckpt  0.07bv1.ckpt  0.07bv3.ckpt\t0.08.ckpt  Model.ckpt\n0.06bv1.ckpt  0.07.ckpt     0.07bv2.ckpt  0.07bv4.ckpt\t0.11.ckpt\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}